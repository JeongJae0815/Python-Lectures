{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdf5 is not supported on this machine (please install/reinstall h5py for optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import pandas\n",
    "import sys\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import csv\n",
    "import datetime\n",
    "import collections\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adverserial Networks (GANs)\n",
    "\n",
    "Highlighted by Yann Le Cun as one of *the* big developments in deep learning in the past couple of years, GANs have taken off big.\n",
    "\n",
    "They were developed by Ian Goodfellow (a lead author on the new Deep Learning book http://www.deeplearningbook.org/) and have since then been extended in several applications.\n",
    "\n",
    "Here is the classic publication from 2014:\n",
    "\n",
    "Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A. and Bengio, Y., 2014. Generative adversarial nets. In Advances in neural information processing systems (pp. 2672-2680).\n",
    "\n",
    "In order to solve a certain task, a learning algorithms needs to be able to capture the relevant distributions of the data. In general, we have two approaches:\n",
    "\n",
    "* discriminative approach: here we try to train a network that maps the input data $x$ to some desired output class label $y$. In probabilistic terms, this directly learns the conditional distribution $P(y|x)$.\n",
    "\n",
    "* generative approach: we learn the joint probability distribution of the input data and labels simultaneously, i.e. $P(x,y)$. This can be converted to $P(y|x)$ for classification via Bayes' rule, of course. Importantly, however, we can use $P(x,y)$ to create new samples $(x,y)$ that have highlikelihood.\n",
    "\n",
    "So far, we have used discriminative approaches in our DNNs.\n",
    "\n",
    "What about combining the two approaches?\n",
    "\n",
    "The basic idea of GANs is to let the two fight against each other. You have one generator that takes noise samples and tries to turn them into something that can fool a discriminator into thinking it belongs to one of the actual training samples. Both networks are trained together - in competition - and you use gradient updates from the discriminator to update the generator!\n",
    "\n",
    "![title](images/gan.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# execution mode\n",
    "training=False\n",
    "\n",
    "# let's get MNIST - this is NOT one-hot encoded\n",
    "import tflearn.datasets.mnist as mnist\n",
    "X, Y, testX, testY = mnist.load_data()\n",
    "\n",
    "# this is the input dimension for the discriminator\n",
    "image_dim = 784 # 28*28 pixels\n",
    "\n",
    "# this is the input dimension for the generator and\n",
    "# determines the number of noise data points\n",
    "z_dim = 200 \n",
    "\n",
    "# how many samples we have in our training data?\n",
    "total_samples = len(X)\n",
    "\n",
    "\n",
    "# generator network\n",
    "def generator(x):\n",
    "    # this uses the tensorflow scope to define a set of networks\n",
    "    # whose parameters will exist as named, global variables\n",
    "    # hence, if reuse is True, the weights are shared across \n",
    "    # different calls!!! here, we don't need that\n",
    "    with tf.variable_scope('Generator', reuse=False):\n",
    "        # we add a standard hidden layer\n",
    "        x = tflearn.fully_connected(x, 256, activation='relu')\n",
    "        # and this guy should give us a picture in the end!\n",
    "        x = tflearn.fully_connected(x, image_dim, activation='sigmoid')\n",
    "        return x\n",
    "\n",
    "\n",
    "# discriminator network - note the reuse parameter!!\n",
    "def discriminator(x, reuse=False):\n",
    "    # this uses the tensorflow scope to define a set of networks\n",
    "    # whose parameters will exist as named, global variables\n",
    "    # hence, if reuse is True, the weights are shared across \n",
    "    # different calls!!!\n",
    "    with tf.variable_scope('Discriminator', reuse=reuse):\n",
    "        # we add a standard hidden layer\n",
    "        x = tflearn.fully_connected(x, 256, activation='relu')\n",
    "        # and this guy should give tell us whether it was a fake or a real picture!!\n",
    "        x = tflearn.fully_connected(x, 1, activation='sigmoid')\n",
    "        return x\n",
    "\n",
    "# let's set up the two networks\n",
    "\n",
    "# the generator input consists of noise sampled from a z_dim-dimensional\n",
    "# noise distribution\n",
    "gen_input = tflearn.input_data(shape=[None, z_dim], name='input_noise')\n",
    "\n",
    "# the discriminator input consists of digit pictures\n",
    "disc_input = tflearn.input_data(shape=[None, 784], name='disc_input')\n",
    "\n",
    "# we now add the generator layer - this will produce a picture\n",
    "gen_sample = generator(gen_input)\n",
    "\n",
    "# this will be used for the proper MNIST digit pictures:\n",
    "disc_real = discriminator(disc_input)\n",
    "\n",
    "# here comes the trick: we use the SAME network from the MNIST pictures\n",
    "# to classify the generated sample from the generator network\n",
    "# *****note the reuse parameter!!*****\n",
    "disc_fake = discriminator(gen_sample, reuse=True)\n",
    "\n",
    "# we also need to define how to train all networks\n",
    "# the discriminator network loss should weight both the real loss on\n",
    "# the actual MNIST digit pictures (tf.log(disc_real)) and should be \n",
    "# punished by the loss on the fake digit pictures (tf.log(disc_fake))\n",
    "disc_loss = -tf.reduce_mean(tf.log(disc_real) + tf.log(1. - disc_fake))\n",
    "\n",
    "# the generator loss is solely driven by the on the fake pictures, since\n",
    "# of course it tries to make these as well as possible! In other words,\n",
    "# the generator needs to fool the discriminator!\n",
    "gen_loss = -tf.reduce_mean(tf.log(disc_fake))\n",
    "\n",
    "# let's train both networks against each other\n",
    "# we need to be careful that each network optimization should only \n",
    "# update its own variable - for this, we retrieve each network's \n",
    "# variables (with get_layer_variables_by_scope) and set\n",
    "# 'placeholder=None' because we do not need to feed any target.\n",
    "\n",
    "# get the optimization variables for the generator network:\n",
    "gen_vars = tflearn.get_layer_variables_by_scope('Generator')\n",
    "gen_model = tflearn.regression(gen_sample, placeholder=None, optimizer='adam',\n",
    "                               loss=gen_loss, trainable_vars=gen_vars,\n",
    "                               batch_size=64, name='target_gen', op_name='GEN')\n",
    "\n",
    "# get the optimization variables for the discriminator network:\n",
    "disc_vars = tflearn.get_layer_variables_by_scope('Discriminator')\n",
    "disc_model = tflearn.regression(disc_real, placeholder=None, optimizer='adam',\n",
    "                                loss=disc_loss, trainable_vars=disc_vars,\n",
    "                                batch_size=64, name='target_disc', op_name='DISC')\n",
    "\n",
    "# and define the GAN model, that outputs the generated images\n",
    "# importantly, the GAN model uses the fake loss, which means that it also \n",
    "# will update the discriminator model in each step\n",
    "gan = tflearn.DNN(gen_model)\n",
    "\n",
    "if (training):\n",
    "    # Training\n",
    "    # Generate noise to feed to the generator - this is simply uniformly\n",
    "    # distributed noise between -1 and 1\n",
    "    z = np.random.uniform(-1., 1., size=[total_samples, z_dim])\n",
    "    # Start training, feed both noise and real images as inputs to both\n",
    "    # networks - we train for 100 epochs\n",
    "    gan.fit(X_inputs={gen_input: z, disc_input: X},\n",
    "            Y_targets=None,\n",
    "            n_epoch=100)\n",
    "    gan.save('ganTrained.tflearn')\n",
    "else:\n",
    "    # Sampling\n",
    "    gan.load('ganTrained.tflearn')\n",
    "    # Generate 20 images from noise, using the generator network.\n",
    "    f, a = plt.subplots(2, 10, figsize=(10, 4))\n",
    "    for i in range(10):\n",
    "        for j in range(2):\n",
    "            # Same as before - now we just put in one noise image\n",
    "            z = np.random.uniform(-1., 1., size=[1, z_dim])\n",
    "            # we use the gan network to \"predict\", that is to create an image\n",
    "            # this is extended three times, since matplotlib requires 3 channels\n",
    "            temp = [[ii, ii, ii] for ii in list(gan.predict([z])[0])]\n",
    "            a[j][i].imshow(np.reshape(temp, (28, 28, 3)))\n",
    "    f.show()\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 8927  | time: 4.002s\n",
      "\u001b[2K\r",
      "| GEN | epoch: 011 | loss: 0.00000 -- iter: 20928/55000\n",
      "\u001b[2K\r",
      "| DISC | epoch: 011 | loss: 0.00000 -- iter: 20928/55000\n"
     ]
    }
   ],
   "source": [
    "# execution mode\n",
    "training=True\n",
    "\n",
    "# let's get MNIST - this is NOT one-hot encoded\n",
    "import tflearn.datasets.mnist as mnist\n",
    "X, Y, testX, testY = mnist.load_data()\n",
    "\n",
    "# this is the input dimension for the discriminator\n",
    "image_dim = 784 # 28*28 pixels\n",
    "\n",
    "# this is the input dimension for the generator and\n",
    "# determines the number of noise data points\n",
    "z_dim = 200 \n",
    "\n",
    "# how many samples we have in our training data?\n",
    "total_samples = len(X)\n",
    "\n",
    "\n",
    "# generator network\n",
    "def generator(x):\n",
    "    # this uses the tensorflow scope to define a set of networks\n",
    "    # whose parameters will exist as named, global variables\n",
    "    # hence, if reuse is True, the weights are shared across \n",
    "    # different calls!!! here, we don't need that\n",
    "    with tf.variable_scope('Generator', reuse=False):\n",
    "        # we add a standard hidden layer\n",
    "        x = tflearn.fully_connected(x, 256, activation='relu')\n",
    "        # and this guy should give us a picture in the end!\n",
    "        x = tflearn.fully_connected(x, image_dim, activation='sigmoid')\n",
    "        return x\n",
    "\n",
    "\n",
    "# discriminator network - note the reuse parameter!!\n",
    "def discriminator(x, reuse=False):\n",
    "    # this uses the tensorflow scope to define a set of networks\n",
    "    # whose parameters will exist as named, global variables\n",
    "    # hence, if reuse is True, the weights are shared across \n",
    "    # different calls!!!\n",
    "    with tf.variable_scope('Discriminator', reuse=reuse):\n",
    "        # we add a standard hidden layer\n",
    "        x = tflearn.fully_connected(x, 256, activation='relu')\n",
    "        # and this guy should give tell us whether it was a fake or a real picture!!\n",
    "        x = tflearn.fully_connected(x, 1, activation='sigmoid')\n",
    "        return x\n",
    "\n",
    "# let's set up the two networks\n",
    "\n",
    "# the generator input consists of noise sampled from a z_dim-dimensional\n",
    "# noise distribution\n",
    "gen_input = tflearn.input_data(shape=[None, z_dim], name='input_noise')\n",
    "\n",
    "# the discriminator input consists of digit pictures\n",
    "disc_input = tflearn.input_data(shape=[None, 784], name='disc_input')\n",
    "\n",
    "# we now add the generator layer - this will produce a picture\n",
    "gen_sample = generator(gen_input)\n",
    "\n",
    "# this will be used for the proper MNIST digit pictures:\n",
    "disc_real = discriminator(disc_input)\n",
    "\n",
    "# here comes the trick: we use the SAME network from the MNIST pictures\n",
    "# to classify the generated sample from the generator network\n",
    "# *****note the reuse parameter!!*****\n",
    "disc_fake = discriminator(gen_sample, reuse=True)\n",
    "\n",
    "# we also need to define how to train all networks\n",
    "# the discriminator network loss should weight both the real loss on\n",
    "# the actual MNIST digit pictures (tf.log(disc_real)) and should be \n",
    "# punished by the loss on the fake digit pictures (tf.log(disc_fake))\n",
    "disc_loss = -tf.reduce_mean(tf.log(disc_real) + tf.log(1. - disc_fake))\n",
    "\n",
    "# the generator loss is solely driven by the on the fake pictures, since\n",
    "# of course it tries to make these as well as possible! In other words,\n",
    "# the generator needs to fool the discriminator!\n",
    "gen_loss = -tf.reduce_mean(tf.log(disc_fake))\n",
    "\n",
    "# let's train both networks against each other\n",
    "# we need to be careful that each network optimization should only \n",
    "# update its own variable - for this, we retrieve each network's \n",
    "# variables (with get_layer_variables_by_scope) and set\n",
    "# 'placeholder=None' because we do not need to feed any target.\n",
    "\n",
    "# get the optimization variables for the generator network:\n",
    "gen_vars = tflearn.get_layer_variables_by_scope('Generator')\n",
    "gen_model = tflearn.regression(gen_sample, placeholder=None, optimizer='adam',\n",
    "                               loss=gen_loss, trainable_vars=gen_vars,\n",
    "                               batch_size=64, name='target_gen', op_name='GEN')\n",
    "\n",
    "# get the optimization variables for the discriminator network:\n",
    "disc_vars = tflearn.get_layer_variables_by_scope('Discriminator')\n",
    "disc_model = tflearn.regression(disc_real, placeholder=None, optimizer='adam',\n",
    "                                loss=disc_loss, trainable_vars=disc_vars,\n",
    "                                batch_size=64, name='target_disc', op_name='DISC')\n",
    "\n",
    "# and define the GAN model, that outputs the generated images\n",
    "# importantly, the GAN model uses the fake loss, which means that it also \n",
    "# will update the discriminator model in each step\n",
    "gan = tflearn.DNN(gen_model)\n",
    "\n",
    "disc = tflearn.DNN(disc_model)\n",
    "\n",
    "# Training\n",
    "# Generate noise to feed to the generator - this is simply uniformly\n",
    "# distributed noise between -1 and 1\n",
    "z = np.random.uniform(-1., 1., size=[total_samples, z_dim])\n",
    "# Start training, feed both noise and real images as inputs to both\n",
    "# networks - we train for 100 epochs\n",
    "gan.fit(X_inputs={gen_input: z, disc_input: X},\n",
    "        Y_targets=None,\n",
    "        n_epoch=100)\n",
    "gan.save('ganTrained1.tflearn')\n",
    "disc.save('discTrained1.tflearn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
